# HR Analytics: Job Change of Data Scientists Prediction

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![NumPy](https://img.shields.io/badge/Library-NumPy-orange)
![Status](https://img.shields.io/badge/Status-Completed-green)

## ğŸ“‘ Má»¥c Lá»¥c
1. [Giá»›i thiá»‡u](#1-giá»›i-thiá»‡u)
2. [Dataset](#2-dataset)
3. [PhÆ°Æ¡ng phÃ¡p & Thuáº­t toÃ¡n](#3-phÆ°Æ¡ng-phÃ¡p--thuáº­t-toÃ¡n)
4. [CÃ i Ä‘áº·t & HÆ°á»›ng dáº«n sá»­ dá»¥ng](#4-cÃ i-Ä‘áº·t--hÆ°á»›ng-dáº«n-sá»­-dá»¥ng)
5. [Káº¿t quáº£ thá»±c nghiá»‡m](#5-káº¿t-quáº£-thá»±c-nghiá»‡m)
6. [Cáº¥u trÃºc dá»± Ã¡n](#6-cáº¥u-trÃºc-dá»±-Ã¡n)
7. [ThÃ¡ch thá»©c & Giáº£i phÃ¡p](#7-thÃ¡ch-thá»©c--giáº£i-phÃ¡p)
8. [HÆ°á»›ng phÃ¡t triá»ƒn (Future Improvements)](#8-hÆ°á»›ng-phÃ¡t-triá»ƒn-future-improvements)
9. [ThÃ´ng tin tÃ¡c giáº£](#9-thÃ´ng-tin-tÃ¡c-giáº£)
10. [ÄÃ³ng gÃ³p (Contributors)](#10-Ä‘Ã³ng-gÃ³p-contributors)
11. [LiÃªn há»‡ (Contact)](#11-liÃªn-há»‡-contact)
12. [Giáº¥y phÃ©p (License)](#12-giáº¥y-phÃ©p-license)

---

## 1. Giá»›i thiá»‡u

### 1.1. MÃ´ táº£ bÃ i toÃ¡n
Trong bá»‘i cáº£nh khoa há»c dá»¯ liá»‡u Ä‘ang phÃ¡t triá»ƒn máº¡nh, cÃ¡c cÃ´ng ty Ä‘á»‘i máº·t vá»›i váº¥n Ä‘á» nhÃ¢n sá»± ("churn") khi cÃ¡c Data Scientist thÆ°á»ng xuyÃªn thay Ä‘á»•i cÃ´ng viá»‡c. Dá»± Ã¡n nÃ y xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh Machine Learning Ä‘á»ƒ dá»± Ä‘oÃ¡n xÃ¡c suáº¥t má»™t á»©ng viÃªn sáº½ **thay Ä‘á»•i cÃ´ng viá»‡c** hay khÃ´ng, dá»±a trÃªn cÃ¡c thÃ´ng tin nhÃ¢n kháº©u há»c vÃ  kinh nghiá»‡m cá»§a há».

### 1.2. Äá»™ng lá»±c & Má»¥c tiÃªu
- **Äá»™ng lá»±c:** GiÃºp bá»™ pháº­n HR tá»‘i Æ°u hÃ³a quy trÃ¬nh tuyá»ƒn dá»¥ng, giáº£m chi phÃ­ Ä‘Ã o táº¡o báº±ng cÃ¡ch xÃ¡c Ä‘á»‹nh á»©ng viÃªn cÃ³ Ã½ Ä‘á»‹nh gáº¯n bÃ³ lÃ¢u dÃ i.
- **Má»¥c tiÃªu ká»¹ thuáº­t:**
    - XÃ¢y dá»±ng quy trÃ¬nh Data Pipeline hoÃ n chá»‰nh (ETL, Preprocessing, Modeling).
    - **Äáº·c biá»‡t:** CÃ i Ä‘áº·t thuáº­t toÃ¡n **Logistic Regression tá»« con sá»‘ 0 (From Scratch)**.
    - **RÃ ng buá»™c:** Chá»‰ sá»­ dá»¥ng thÆ° viá»‡n **NumPy** Ä‘á»ƒ xá»­ lÃ½ ma tráº­n vÃ  tá»‘i Æ°u hÃ³a tÃ­nh toÃ¡n (KhÃ´ng dÃ¹ng Pandas cho khÃ¢u xá»­ lÃ½ dá»¯ liá»‡u chÃ­nh).

---

## 2. Dataset

- **Nguá»“n dá»¯ liá»‡u:** [Kaggle - HR Analytics: Job Change of Data Scientists](https://www.kaggle.com/datasets/arashnic/hr-analytics-job-change-of-data-scientists)
- **KÃ­ch thÆ°á»›c:** ~19,158 dÃ²ng (Training set).
- **Äáº·c trÆ°ng (Features):** 13 cá»™t, bao gá»“m dá»¯ liá»‡u há»—n há»£p:
    - *Äá»‹nh lÆ°á»£ng:* `city_development_index`, `training_hours`.
    - *Äá»‹nh tÃ­nh/PhÃ¢n loáº¡i:* `gender`, `relevent_experience`, `enrolled_university`, `major_discipline`.
    - *CÃ³ thá»© tá»± (Ordinal):* `education_level`, `company_size`, `experience`.
- **Biáº¿n má»¥c tiÃªu (Target):** `0` (KhÃ´ng Ä‘á»•i viá»‡c) vÃ  `1` (Muá»‘n Ä‘á»•i viá»‡c).

---

## 3. PhÆ°Æ¡ng phÃ¡p & Thuáº­t toÃ¡n

### 3.1. Xá»­ lÃ½ dá»¯ liá»‡u (Pure NumPy Implementation)
Do khÃ´ng sá»­ dá»¥ng Pandas, quy trÃ¬nh xá»­ lÃ½ dá»¯ liá»‡u Ä‘Æ°á»£c thá»±c hiá»‡n thá»§ cÃ´ng thÃ´ng qua cÃ¡c ká»¹ thuáº­t thao tÃ¡c máº£ng (Array Manipulation):

1.  **Loading Data:** Sá»­ dá»¥ng `np.genfromtxt` vá»›i `dtype=None` vÃ  `encoding='utf-8'` Ä‘á»ƒ Ä‘á»c dá»¯ liá»‡u há»—n há»£p.
2.  **Handling Missing Values:**
    - Biáº¿n sá»‘: Thay tháº¿ báº±ng `np.nanmean` (Mean).
    - Biáº¿n phÃ¢n loáº¡i: Thay tháº¿ báº±ng giÃ¡ trá»‹ xuáº¥t hiá»‡n nhiá»u nháº¥t (Mode) hoáº·c táº¡o nhÃ³m `'Unknown'`.
3.  **Feature Engineering (KhÃ³ khÄƒn nháº¥t):**
    - `Experience`: Xá»­ lÃ½ cÃ¡c chuá»—i kÃ½ tá»± Ä‘áº·c biá»‡t (`>20` $\rightarrow$ 21, `<1` $\rightarrow$ 0) báº±ng ká»¹ thuáº­t masking.
    - `Company Size`: Ãnh xáº¡ (Mapping) thá»§ cÃ´ng sang thang Ä‘o thá»© tá»± (Ordinal Encoding) tá»« 0 Ä‘áº¿n 7.
    - `City`: TÃ¡ch chuá»—i `city_103` Ä‘á»ƒ láº¥y mÃ£ vÃ¹ng `103` lÃ m feature sá»‘.
4.  **Normalization:** Ãp dá»¥ng Min-Max Scaling Ä‘á»ƒ Ä‘Æ°a táº¥t cáº£ feature vá» Ä‘oáº¡n $[0, 1]$, giÃºp Gradient Descent há»™i tá»¥ nhanh hÆ¡n.

### 3.2. Thuáº­t toÃ¡n: Logistic Regression (From Scratch)
MÃ´ hÃ¬nh Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn ná»n táº£ng toÃ¡n há»c:

- **HÃ m giáº£ thuyáº¿t (Hypothesis):** Sá»­ dá»¥ng hÃ m Sigmoid.
  $$\hat{y} = \sigma(z) = \frac{1}{1 + e^{-z}}$$
  Trong Ä‘Ã³: $z = X \cdot w + b$

- **HÃ m máº¥t mÃ¡t (Cost Function):** Binary Cross-Entropy Loss.
  $$J(w,b) = -\frac{1}{m} \sum_{i=1}^{m} [y^{(i)}\log(\hat{y}^{(i)}) + (1-y^{(i)})\log(1-\hat{y}^{(i)})]$$

- **Tá»‘i Æ°u hÃ³a (Optimization):** Gradient Descent.
  Cáº­p nháº­t trá»ng sá»‘ $w$ vÃ  bias $b$ sau má»—i vÃ²ng láº·p:
  $$dw = \frac{1}{m} X^T (\hat{y} - y)$$
  $$db = \frac{1}{m} \sum (\hat{y} - y)$$
  $$w = w - \alpha \cdot dw$$

- **Ká»¹ thuáº­t Vectorization:**
  Thay vÃ¬ dÃ¹ng vÃ²ng láº·p `for` Ä‘á»ƒ duyá»‡t qua tá»«ng máº«u dá»¯ liá»‡u (ráº¥t cháº­m), mÃ´ hÃ¬nh sá»­ dá»¥ng phÃ©p nhÃ¢n ma tráº­n (`np.dot`) Ä‘á»ƒ tÃ­nh toÃ¡n trÃªn toÃ n bá»™ táº­p dá»¯ liá»‡u cÃ¹ng lÃºc, tÄƒng hiá»‡u suáº¥t lÃªn hÃ ng trÄƒm láº§n.

  ### 3.3. CÃ¢n báº±ng dá»¯ liá»‡u (SMOTE from Scratch)
Äá»ƒ giáº£i quyáº¿t váº¥n Ä‘á» máº¥t cÃ¢n báº±ng dá»¯ liá»‡u nghiÃªm trá»ng, thuáº­t toÃ¡n **SMOTE (Synthetic Minority Over-sampling Technique)** Ä‘Æ°á»£c cÃ i Ä‘áº·t thá»§ cÃ´ng:
- **NguyÃªn lÃ½:** TÃ­nh toÃ¡n khoáº£ng cÃ¡ch Euclidean giá»¯a cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u thiá»ƒu sá»‘, tÃ¬m k-lÃ¡ng giá»ng gáº§n nháº¥t (KNN) vÃ  ná»™i suy tuyáº¿n tÃ­nh Ä‘á»ƒ sinh ra cÃ¡c máº«u dá»¯ liá»‡u má»›i.
- **Ká»¹ thuáº­t NumPy:** Sá»­ dá»¥ng Broadcasting Ä‘á»ƒ tÃ­nh ma tráº­n khoáº£ng cÃ¡ch mÃ  khÃ´ng cáº§n vÃ²ng láº·p lá»“ng nhau, tÄƒng tá»‘c Ä‘á»™ xá»­ lÃ½.

---

## 4. CÃ i Ä‘áº·t & HÆ°á»›ng dáº«n sá»­ dá»¥ng

### 4.1. YÃªu cáº§u há»‡ thá»‘ng
- Python 3.8+
- ThÆ° viá»‡n: NumPy, Matplotlib, Seaborn.

### 4.2. CÃ i Ä‘áº·t
```bash
# 1. Clone repository
git clone https://github.com/trungkienjjj/HR_Analytics_Project.git
cd HR_Analytics_Project

# 2. CÃ i Ä‘áº·t thÆ° viá»‡n
pip install -r requirements.txt
```

### 4.3. Cháº¡y chÆ°Æ¡ng trÃ¬nh
Dá»± Ã¡n Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ cháº¡y tuáº§n tá»± qua cÃ¡c Jupyter Notebook trong thÆ° má»¥c `notebooks/`:

1.  **BÆ°á»›c 1:** Má»Ÿ `notebooks/01_data_exploration.ipynb`
    - Cháº¡y toÃ n bá»™ Ä‘á»ƒ táº£i dá»¯ liá»‡u vÃ  xem thá»‘ng kÃª mÃ´ táº£, biá»ƒu Ä‘á»“ phÃ¢n phá»‘i cÃ¡c Ä‘áº·c trÆ°ng.
2.  **BÆ°á»›c 2:** Má»Ÿ `notebooks/02_preprocessing.ipynb`
    - Cháº¡y Ä‘á»ƒ lÃ m sáº¡ch dá»¯ liá»‡u, xá»­ lÃ½ missing values, chuáº©n hÃ³a (Min-Max Scaling) vÃ  mÃ£ hÃ³a (Encoding).
    - Káº¿t quáº£ sáº½ táº¡o ra cÃ¡c file `.npy` trong thÆ° má»¥c `data/processed/`.
3.  **BÆ°á»›c 3:** Má»Ÿ `notebooks/03_modeling.ipynb`
    - Cháº¡y Ä‘á»ƒ load dá»¯ liá»‡u sáº¡ch, huáº¥n luyá»‡n mÃ´ hÃ¬nh Logistic Regression tá»± viáº¿t vÃ  Ä‘Ã¡nh giÃ¡ káº¿t quáº£.

---

## 5. Káº¿t quáº£ thá»±c nghiá»‡m

### 5.1. Báº£ng so sÃ¡nh hiá»‡u nÄƒng (Performance Comparison)

DÆ°á»›i Ä‘Ã¢y lÃ  báº£ng so sÃ¡nh giá»¯a mÃ´ hÃ¬nh **Logistic Regression tá»± cÃ i Ä‘áº·t (NumPy)** vÃ  mÃ´ hÃ¬nh thÆ° viá»‡n chuáº©n (Scikit-learn).

| Metric | Custom Model (NumPy) | Sklearn (Baseline) | Nháº­n xÃ©t |
| :--- | :---: | :---: | :--- |
| **Accuracy** | 0.6587 | **0.7784** | Sklearn tá»‘t hÆ¡n vá» Ä‘á»™ chÃ­nh xÃ¡c tá»•ng thá»ƒ (do thiÃªn vá» lá»›p Ä‘a sá»‘). |
| **Precision**| 0.3851 | **0.6105** | Sklearn Ã­t bÃ¡o Ä‘á»™ng giáº£ hÆ¡n. |
| **Recall** | **0.6316** | 0.2937 | **QUAN TRá»ŒNG:** Model NumPy phÃ¡t hiá»‡n Ä‘Æ°á»£c **gáº¥p Ä‘Ã´i** sá»‘ ngÆ°á»i muá»‘n nghá»‰ viá»‡c so vá»›i Sklearn. |
| **F1-Score** | **0.4785** | 0.3966 | Model NumPy cÃ¢n báº±ng tá»‘t hÆ¡n trÃªn dá»¯ liá»‡u lá»‡ch. |

> **Káº¿t luáº­n:**
> Máº·c dÃ¹ Accuracy tháº¥p hÆ¡n, mÃ´ hÃ¬nh tá»± xÃ¢y dá»±ng (cÃ³ Ã¡p dá»¥ng SMOTE vÃ  tinh chá»‰nh tham sá»‘) Ä‘áº¡t **Recall** vÃ  **F1-Score** cao hÆ¡n Ä‘Ã¡ng ká»ƒ. Trong bá»‘i cáº£nh bÃ i toÃ¡n nhÃ¢n sá»± ("thÃ  báº¯t nháº§m cÃ²n hÆ¡n bá» sÃ³t ngÆ°á»i tÃ i"), mÃ´ hÃ¬nh Custom mang láº¡i giÃ¡ trá»‹ thá»±c tiá»…n cao hÆ¡n.

### 5.2. Trá»±c quan hÃ³a quÃ¡ trÃ¬nh huáº¥n luyá»‡n
DÆ°á»›i Ä‘Ã¢y lÃ  biá»ƒu Ä‘á»“ Learning Curve (trÃ¡i) vÃ  Confusion Matrix (pháº£i) Ä‘Æ°á»£c lÆ°u tá»± Ä‘á»™ng tá»« quÃ¡ trÃ¬nh huáº¥n luyá»‡n:

![Training Result](IMG/training_result.png)

---

## 6. Cáº¥u trÃºc dá»± Ã¡n

```text
HR_Analytics_Project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Dá»¯ liá»‡u gá»‘c (CSV)
â”‚   â””â”€â”€ processed/          # Dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½ (.npy)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb  # EDA
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb     # Preprocessing
â”‚   â””â”€â”€ 03_modeling.ipynb          # Modeling & Evaluation
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_processing.py  # CÃ¡c hÃ m xá»­ lÃ½ dá»¯ liá»‡u
â”‚   â”œâ”€â”€ visualization.py    # CÃ¡c hÃ m váº½ biá»ƒu Ä‘á»“
â”‚   â””â”€â”€ models.py           # Logistic Regression & SMOTE
â”œâ”€â”€ IMG/                    # Chá»©a áº£nh káº¿t quáº£ training/evaluation
â”œâ”€â”€ LICENSE                 # Giáº¥y phÃ©p MIT
â”œâ”€â”€ README.md               # TÃ i liá»‡u bÃ¡o cÃ¡o
â””â”€â”€ requirements.txt        # ThÆ° viá»‡n cáº§n thiáº¿t
```

---

## 7. ThÃ¡ch thá»©c & Giáº£i phÃ¡p

Trong quÃ¡ trÃ¬nh thá»±c hiá»‡n dá»± Ã¡n vá»›i yÃªu cáº§u kháº¯t khe lÃ  **"CHá»ˆ sá»­ dá»¥ng NumPy"** (khÃ´ng Pandas), nhÃ³m Ä‘Ã£ Ä‘á»‘i máº·t vÃ  giáº£i quyáº¿t cÃ¡c thÃ¡ch thá»©c ká»¹ thuáº­t sau:

1.  **Xá»­ lÃ½ dá»¯ liá»‡u há»—n há»£p (Mixed Data Types):**
    - *Váº¥n Ä‘á»:* Máº£ng NumPy (`ndarray`) tá»‘i Æ°u cho dá»¯ liá»‡u Ä‘á»“ng nháº¥t (sá»‘ toÃ n bá»™). Tuy nhiÃªn, táº­p dá»¯ liá»‡u nhÃ¢n sá»± chá»©a cáº£ sá»‘ nguyÃªn, sá»‘ thá»±c vÃ  chuá»—i kÃ½ tá»±.
    - *Giáº£i phÃ¡p:* Sá»­ dá»¥ng `dtype=None` vÃ  `encoding='utf-8'` khi load dá»¯ liá»‡u Ä‘á»ƒ NumPy tá»± Ä‘á»™ng nháº­n diá»‡n. Sau Ä‘Ã³, tÃ¡ch cÃ¡c cá»™t chuá»—i ra xá»­ lÃ½ riÃªng (Ã©p kiá»ƒu, cáº¯t chuá»—i báº±ng `np.char`) rá»“i má»›i gá»™p láº¡i vÃ o ma tráº­n tÃ­nh toÃ¡n báº±ng `np.column_stack`.

2.  **Tá»‘i Æ°u hÃ³a tá»‘c Ä‘á»™ (Vectorization):**
    - *Váº¥n Ä‘á»:* Viá»‡c dÃ¹ng vÃ²ng láº·p `for` Ä‘á»ƒ tÃ­nh toÃ¡n Gradient Descent cho gáº§n 20.000 máº«u dá»¯ liá»‡u khiáº¿n thuáº­t toÃ¡n cháº¡y ráº¥t cháº­m.
    - *Giáº£i phÃ¡p:* Loáº¡i bá» hoÃ n toÃ n vÃ²ng láº·p xá»­ lÃ½ máº«u. Chuyá»ƒn Ä‘á»•i cÃ´ng thá»©c toÃ¡n há»c sang dáº¡ng phÃ©p nhÃ¢n ma tráº­n (`np.dot`), táº­n dá»¥ng kháº£ nÄƒng tÃ­nh toÃ¡n song song cá»§a NumPy Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™ xá»­ lÃ½ lÃªn gáº¥p nhiá»u láº§n.

3.  **Äá»™ á»•n Ä‘á»‹nh sá»‘ há»c (Numerical Stability):**
    - *Váº¥n Ä‘á»:* HÃ m `log` trong cÃ´ng thá»©c Binary Cross-Entropy sáº½ tráº£ vá» `-inf` (lá»—i chia cho 0) náº¿u mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n xÃ¡c suáº¥t tuyá»‡t Ä‘á»‘i lÃ  0 hoáº·c 1.
    - *Giáº£i phÃ¡p:* ThÃªm má»™t giÃ¡ trá»‹ cá»±c nhá» `epsilon` ($1e-9$) vÃ o trong hÃ m log (`np.log(y_pred + epsilon)`) Ä‘á»ƒ Ä‘áº£m báº£o tÃ­nh toÃ¡n luÃ´n an toÃ n.

4.  **Dá»¯ liá»‡u máº¥t cÃ¢n báº±ng (Imbalanced Class):**
    - *Váº¥n Ä‘á»:* Lá»›p "Muá»‘n Ä‘á»•i viá»‡c" (1) quÃ¡ Ã­t dáº«n Ä‘áº¿n mÃ´ hÃ¬nh cÃ³ xu hÆ°á»›ng dá»± Ä‘oÃ¡n toÃ n bá»™ lÃ  lá»›p 0 (Accuracy cao áº£o nhÆ°ng Recall tháº¥p).
    - *Giáº£i phÃ¡p:* Tá»± cÃ i Ä‘áº·t thuáº­t toÃ¡n **SMOTE** báº±ng NumPy Ä‘á»ƒ sinh dá»¯ liá»‡u nhÃ¢n táº¡o, giÃºp cÃ¢n báº±ng tá»· lá»‡ máº«u giá»¯a hai lá»›p, qua Ä‘Ã³ cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ chá»‰ sá»‘ Recall.

---

## 8. HÆ°á»›ng phÃ¡t triá»ƒn (Future Improvements)

Máº·c dÃ¹ dá»± Ã¡n Ä‘Ã£ hoÃ n thÃ nh cÃ¡c má»¥c tiÃªu cÆ¡ báº£n, váº«n cÃ²n nhiá»u dÆ° Ä‘á»‹a Ä‘á»ƒ cáº£i tiáº¿n:

1.  **Tá»‘i Æ°u hÃ³a thuáº­t toÃ¡n (Advanced Optimization):**
    - CÃ i Ä‘áº·t thÃªm cÃ¡c thuáº­t toÃ¡n tá»‘i Æ°u nÃ¢ng cao nhÆ° **Adam** hoáº·c **RMSProp** (thay vÃ¬ Gradient Descent cÆ¡ báº£n) Ä‘á»ƒ mÃ´ hÃ¬nh há»™i tá»¥ nhanh hÆ¡n.
    - Triá»ƒn khai **Mini-batch Gradient Descent** Ä‘á»ƒ xá»­ lÃ½ táº­p dá»¯ liá»‡u lá»›n hiá»‡u quáº£ hÆ¡n vá» bá»™ nhá»›.

2.  **Má»Ÿ rá»™ng mÃ´ hÃ¬nh (Model Expansion):**
    - Thá»­ sá»©c cÃ i Ä‘áº·t **Neural Network (Multi-layer Perceptron)** Ä‘Æ¡n giáº£n tá»« Ä‘áº§u báº±ng NumPy Ä‘á»ƒ náº¯m báº¯t cÃ¡c má»‘i quan há»‡ phi tuyáº¿n tÃ­nh phá»©c táº¡p trong dá»¯ liá»‡u.
    - XÃ¢y dá»±ng cÆ¡ cháº¿ **Grid Search tá»± Ä‘á»™ng** (viáº¿t tay) Ä‘á»ƒ tÃ¬m ra bá»™ tham sá»‘ tá»‘i Æ°u (Learning rate, Lambda, K-neighbors cho SMOTE) thay vÃ¬ thá»­ thá»§ cÃ´ng.

3.  **Triá»ƒn khai (Deployment):**
    - ÄÃ³ng gÃ³i mÃ´ hÃ¬nh thÃ nh API Ä‘Æ¡n giáº£n (sá»­ dá»¥ng Flask/FastAPI) hoáº·c giao diá»‡n web (Streamlit) Ä‘á»ƒ ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ nháº­p thÃ´ng tin vÃ  nháº­n dá»± Ä‘oÃ¡n trá»±c tiáº¿p.

---

## 9. ThÃ´ng tin tÃ¡c giáº£

- **Há» vÃ  tÃªn:** Nguyá»…n Tráº§n Trung KiÃªn
- **MSSV:** 23122038
- **Lá»›p:** TrÃ­ tuá»‡ nhÃ¢n táº¡o (23TNT1)
- **TrÆ°á»ng:** Äáº¡i há»c Khoa há»c Tá»± nhiÃªn, ÄHQG-HCM
- **GitHub:** https://github.com/trungkienjjj
- **Email:** nttkien080925@gmail.com

---

## 10. ÄÃ³ng gÃ³p (Contributors)

Dá»± Ã¡n nÃ y lÃ  bÃ i táº­p cÃ¡ nhÃ¢n, tuy nhiÃªn xin gá»­i lá»i cáº£m Æ¡n Ä‘áº¿n:
- **Giáº£ng viÃªn hÆ°á»›ng dáº«n:** Tháº§y LÃª Nhá»±t Nam Ä‘Ã£ cung cáº¥p kiáº¿n thá»©c ná»n táº£ng vÃ  Ä‘á»‹nh hÆ°á»›ng Ä‘á» tÃ i.
- **Cá»™ng Ä‘á»“ng Kaggle:** ÄÃ£ cung cáº¥p bá»™ dá»¯ liá»‡u *HR Analytics* cháº¥t lÆ°á»£ng.

---

## 11. LiÃªn há»‡ (Contact)

Má»i tháº¯c máº¯c vá» dá»± Ã¡n, vui lÃ²ng liÃªn há»‡ qua:
- **Email tÃ¡c giáº£:** 23122038@student.hcmus.edu.vn
- **Email giáº£ng viÃªn:** lnnam@fit.hcmus.edu.vn

---

## 12. Giáº¥y phÃ©p (License)

Dá»± Ã¡n Ä‘Æ°á»£c phÃ¢n phá»‘i dÆ°á»›i giáº¥y phÃ©p **MIT License**. Xem chi tiáº¿t trong file [LICENSE](./LICENSE).

---
*Dá»± Ã¡n nÃ y lÃ  BÃ i táº­p 2 (Homework 2) thuá»™c mÃ´n há»c Láº­p trÃ¬nh cho Khoa há»c Dá»¯ liá»‡u.*